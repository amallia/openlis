{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openlis usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openlis\n",
    "import openlis.data\n",
    "import openlis.model\n",
    "import openlis.database\n",
    "li = openlis\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Generate a dataset of a 100,000 uniform floats betweeo 0.0 and 1.0\n",
    "\n",
    "num_keys = 100000\n",
    "key_range = [0.0, 1.0]\n",
    "raw_data_set = li.data.generate_uniform_floats_data_set(num_keys, \n",
    "                                                        key_range, \n",
    "                                                        iseed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split into train/validate, using 100% for training (no validation needed)\n",
    "\n",
    "data_sets = li.data.create_train_validate_data_sets(raw_data_set, validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a recursive-model index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create a Recursive-model index based on the training data set\n",
    "\n",
    "rmi = li.model.RMI_simple(data_sets.train,\n",
    "                          hidden_layer_widths=[8,8],\n",
    "                          num_experts=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database interface to that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create a learned index structure, which can be used like a database\n",
    "\n",
    "rmi_db = li.database.IndexStructurePacked(model=rmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 44023.55 (0.052 sec, total 0.052 secs)\n",
      "Step 100: loss = 10698.79 (0.006 sec, total 0.380 secs)\n",
      "Step 200: loss = 4290.76 (0.006 sec, total 0.760 secs)\n",
      "Step 300: loss = 1681.16 (0.007 sec, total 1.106 secs)\n",
      "Step 400: loss = 891.59 (0.006 sec, total 1.495 secs)\n",
      "Step 0: loss = 50030.11 (0.053 sec, total 1.973 secs)\n",
      "Step 100: loss = 543.85 (0.012 sec, total 2.947 secs)\n",
      "Step 200: loss = 195.52 (0.012 sec, total 3.860 secs)\n",
      "Step 300: loss = 195.18 (0.012 sec, total 4.798 secs)\n",
      "Step 400: loss = 183.91 (0.019 sec, total 5.813 secs)\n",
      "INFO:tensorflow:Restoring parameters from tf_checkpoints_example/stage_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "## Train the database\n",
    "\n",
    "# May need to try different batch_sizes, max_steps, learning rates.\n",
    "# Each is an array with two elements (for Stage 1 and Stage 2).\n",
    "\n",
    "# Note that rmi_db.train() not only trains the model, but also\n",
    "# calculates and saves the maximum errors for each \"expert\" and \n",
    "# saves the trained weights and biases for use in fast Numpy \n",
    "# inference calculations. Basically, this function does everything\n",
    "# needed to get Select, Insert, and Delete ready to work.\n",
    "\n",
    "rmi_db.train(batch_sizes=[10000,1000],\n",
    "             max_steps=[500,500],\n",
    "             learning_rates=[0.001,1000],\n",
    "             model_save_dir='tf_checkpoints_example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select, example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select single key:\n",
      " Key: 0.1540215085518002\n",
      " Pos: 15476\n",
      "\n",
      "Select multiple keys:\n",
      "Keys: [ 0.15402151  0.1999664   0.71770092  0.21420649  0.42162701]\n",
      " Pos: [15476 20118 71921 21498 42394]\n",
      "\n",
      "Select non-existing key:\n",
      "Keys: 17.0\n",
      " Pos: -1\n",
      "Note: Pos=-1 indicates that the key is not in the dataset.\n"
     ]
    }
   ],
   "source": [
    "## Use Select, some examples\n",
    "\n",
    "# Select single key\n",
    "keys = np.array(data_sets.train.keys[0])\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Select single key:\")\n",
    "print(\" Key: {}\\n Pos: {}\\n\".format(np.squeeze(keys),np.squeeze(pos)))\n",
    "\n",
    "# Select multiple keys\n",
    "keys = np.array(data_sets.train.keys[0:5])\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Select multiple keys:\")\n",
    "print(\"Keys: {}\\n Pos: {}\\n\".format(np.squeeze(keys),np.squeeze(pos)))\n",
    "\n",
    "# Select non-existing key\n",
    "keys = [17.0]\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Select non-existing key:\")\n",
    "print(\"Keys: {}\\n Pos: {}\".format(np.squeeze(keys),np.squeeze(pos)))\n",
    "\n",
    "print(\"Note: Pos=-1 indicates that the key is not in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert, example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert single key:\n",
      " Success: True\n",
      " Key: 0.5\n",
      " Pos: 50115\n",
      "\n",
      "Insert multiple keys:\n",
      " Success: [ True  True  True  True]\n",
      " Keys: [-17.    0.2   0.8  17. ]\n",
      " Pos: [     0  20121  80189 100004]\n",
      "\n",
      "Insert existing key:\n",
      " Success: False\n",
      " Keys: 0.5\n",
      " Pos: 50117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Use Insert, some examples\n",
    "\n",
    "# Insert single key\n",
    "keys = np.array([0.5])\n",
    "success = rmi_db.insert(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Insert single key:\")\n",
    "print(\" Success: {}\\n Key: {}\\n Pos: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "\n",
    "# Insert multiple keys\n",
    "keys = np.array([-17.0, 0.2, 0.8, 17.0])\n",
    "success = rmi_db.insert(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Insert multiple keys:\")\n",
    "print(\" Success: {}\\n Keys: {}\\n Pos: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "# Insert existing key\n",
    "keys = np.array([0.5])\n",
    "success = rmi_db.insert(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Insert existing key:\")\n",
    "print(\" Success: {}\\n Keys: {}\\n Pos: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete, example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete single key:\n",
      " Success: True\n",
      " Key: 0.5\n",
      " Pos after deletion: -1\n",
      "\n",
      "Delete multiple keys:\n",
      " Success: [ True  True  True  True]\n",
      " Keys: [-17.    0.2   0.8  17. ]\n",
      " Pos after deletion: [-1 -1 -1 -1]\n",
      "\n",
      "Delete non-existing key:\n",
      " Success: False\n",
      " Keys: 0.5\n",
      " Pos after deletion: -1\n",
      "\n",
      "Note: Pos=-1 indicates that the key is not in the dataset.\n"
     ]
    }
   ],
   "source": [
    "## Use Delete, some examples\n",
    "\n",
    "# Delete single key\n",
    "keys = np.array([0.5])\n",
    "success = rmi_db.delete(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Delete single key:\")\n",
    "print(\" Success: {}\\n Key: {}\\n Pos after deletion: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "\n",
    "# Delete multiple keys\n",
    "keys = np.array([-17.0, 0.2, 0.8, 17.0])\n",
    "success = rmi_db.delete(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Delete multiple keys:\")\n",
    "print(\" Success: {}\\n Keys: {}\\n Pos after deletion: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "# Delete non-existing key\n",
    "keys = np.array([0.5])\n",
    "success = rmi_db.delete(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Delete non-existing key:\")\n",
    "print(\" Success: {}\\n Keys: {}\\n Pos after deletion: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "\n",
    "print(\"Note: Pos=-1 indicates that the key is not in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 48241.78 (0.047 sec, total 0.047 secs)\n",
      "Step 100: loss = 18202.67 (0.006 sec, total 0.405 secs)\n",
      "Step 200: loss = 4730.72 (0.006 sec, total 0.796 secs)\n",
      "Step 300: loss = 2723.77 (0.011 sec, total 1.189 secs)\n",
      "Step 400: loss = 1835.27 (0.011 sec, total 1.621 secs)\n",
      "Step 0: loss = 48809.59 (0.062 sec, total 2.258 secs)\n",
      "Step 100: loss = 394.18 (0.012 sec, total 3.199 secs)\n",
      "Step 200: loss = 170.76 (0.012 sec, total 4.129 secs)\n",
      "Step 300: loss = 174.48 (0.021 sec, total 5.144 secs)\n",
      "Step 400: loss = 185.45 (0.013 sec, total 6.193 secs)\n",
      "INFO:tensorflow:Restoring parameters from tf_checkpoints_example/stage_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "## Retrain the model after many insertions and/or deletions.\n",
    "\n",
    "rmi_db.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
