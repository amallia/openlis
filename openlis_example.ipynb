{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openlis usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openlis\n",
    "import openlis.data\n",
    "import openlis.model\n",
    "import openlis.database\n",
    "li = openlis\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Generate a dataset of a 100,000 uniform floats betweeo 0.0 and 1.0\n",
    "\n",
    "num_keys = 100000\n",
    "key_range = [0.0, 1.0]\n",
    "raw_data_set = li.data.generate_uniform_floats(num_keys, \n",
    "                                                        key_range, \n",
    "                                                        iseed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split into train/validate, using 100% for training (no validation needed)\n",
    "\n",
    "data_sets = li.data.create_train_validate_data_sets(raw_data_set, validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a recursive-model index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create a Recursive-model index based on the training data set\n",
    "\n",
    "rmi = li.model.RMI_simple(data_sets.train,\n",
    "                          hidden_layer_widths=[8,8],\n",
    "                          num_experts=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database interface to that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a learned index structure, which can be used like a database.\n",
    "## Choose either IndexStructurePacked or IndexStructureGapped.\n",
    "\n",
    "# IndexStructureGapped is faster for insertions and deletions.\n",
    "rmi_db = li.database.IndexStructureGapped(model=rmi, scale=3)\n",
    "# If using IndexStructureGapped, you can rescale the array at any time.\n",
    "rmi_db.rescale(scale=2)\n",
    "\n",
    "# IndexStructurePacked uses less space.\n",
    "# Uncomment the following code if you want to use IndexStructurePacked.\n",
    "#rmi_db = li.database.IndexStructurePacked(model=rmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Training:\n",
      "Step 0: loss = 84213.62 (0.050 sec, total 0.050 secs)\n",
      "Step 100: loss = 26946.20 (0.008 sec, total 0.565 secs)\n",
      "Step 200: loss = 10828.25 (0.009 sec, total 0.989 secs)\n",
      "Step 300: loss = 7181.41 (0.008 sec, total 1.496 secs)\n",
      "Step 400: loss = 5289.36 (0.006 sec, total 1.966 secs)\n",
      "\n",
      "Stage 2 Training:\n",
      "Step 0: loss = 104121.01 (0.069 sec, total 2.595 secs)\n",
      "Step 100: loss = 22925.52 (0.014 sec, total 3.563 secs)\n",
      "Step 200: loss = 2362.50 (0.012 sec, total 4.733 secs)\n",
      "Step 300: loss = 358.10 (0.014 sec, total 5.783 secs)\n",
      "Step 400: loss = 330.72 (0.015 sec, total 6.952 secs)\n",
      "INFO:tensorflow:Restoring parameters from tf_checkpoints_example/stage_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "## Train the database\n",
    "\n",
    "# May need to try different batch_sizes, max_steps, learning rates.\n",
    "# Each is an array with two elements (for Stage 1 and Stage 2).\n",
    "\n",
    "# Note that rmi_db.train() not only trains the model, but also\n",
    "# calculates and saves the maximum errors for each \"expert\" and \n",
    "# saves the trained weights and biases for use in fast Numpy \n",
    "# inference calculations. Basically, this function does everything\n",
    "# needed to get Select, Insert, and Delete ready to work.\n",
    "\n",
    "rmi_db.train(batch_sizes=[10000,1000],\n",
    "             max_steps=[500,500],\n",
    "             learning_rates=[0.001,1000],\n",
    "             model_save_dir='tf_checkpoints_example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select, example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select single key:\n",
      " Key: 0.1540215085518002\n",
      " Pos: 30952\n",
      "\n",
      "Select multiple keys:\n",
      "Keys: [ 0.15402151  0.1999664   0.71770092  0.21420649  0.42162701]\n",
      " Pos: [ 30952  40236 143842  42996  84788]\n",
      "\n",
      "Select non-existing key:\n",
      "Keys: 17.0\n",
      " Pos: -1\n",
      "Note: Pos=-1 indicates that the key is not in the dataset.\n"
     ]
    }
   ],
   "source": [
    "## Use Select, some examples\n",
    "\n",
    "# Select single key\n",
    "keys = np.array(data_sets.train.keys[0])\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Select single key:\")\n",
    "print(\" Key: {}\\n Pos: {}\\n\".format(np.squeeze(keys),np.squeeze(pos)))\n",
    "\n",
    "# Select multiple keys\n",
    "keys = np.array(data_sets.train.keys[0:5])\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Select multiple keys:\")\n",
    "print(\"Keys: {}\\n Pos: {}\\n\".format(np.squeeze(keys),np.squeeze(pos)))\n",
    "\n",
    "# Select non-existing key\n",
    "keys = [17.0]\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Select non-existing key:\")\n",
    "print(\"Keys: {}\\n Pos: {}\".format(np.squeeze(keys),np.squeeze(pos)))\n",
    "\n",
    "print(\"Note: Pos=-1 indicates that the key is not in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert, example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert single key:\n",
      " Success: True\n",
      " Key: 0.5\n",
      " Pos: 100229\n",
      "\n",
      "Insert multiple keys:\n",
      " Success: [ True  True  True  True  True  True]\n",
      " Keys: [-42.  -17.    0.2   0.8  17.   42. ]\n",
      " Pos: [     0      1  40239 160371 199998 199999]\n",
      "\n",
      "Insert existing key:\n",
      " Success: False\n",
      " Keys: 0.5\n",
      " Pos: 100229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Use Insert, some examples\n",
    "\n",
    "# Insert single key\n",
    "keys = np.array([0.5])\n",
    "success = rmi_db.insert(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Insert single key:\")\n",
    "print(\" Success: {}\\n Key: {}\\n Pos: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "\n",
    "# Insert multiple keys\n",
    "keys = np.array([-42.0, -17.0, 0.2, 0.8, 17.0, 42.0])\n",
    "success = rmi_db.insert(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Insert multiple keys:\")\n",
    "print(\" Success: {}\\n Keys: {}\\n Pos: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "# Insert existing key\n",
    "keys = np.array([0.5])\n",
    "success = rmi_db.insert(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Insert existing key:\")\n",
    "print(\" Success: {}\\n Keys: {}\\n Pos: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete, example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete single key:\n",
      " Success: True\n",
      " Key: 0.5\n",
      " Pos after deletion: -1\n",
      "\n",
      "Delete multiple keys:\n",
      " Success: [ True  True  True  True  True  True]\n",
      " Keys: [-42.  -17.    0.2   0.8  17.   42. ]\n",
      " Pos after deletion: [-1 -1 -1 -1 -1 -1]\n",
      "\n",
      "Delete non-existing key:\n",
      " Success: False\n",
      " Keys: 0.5\n",
      " Pos after deletion: -1\n",
      "\n",
      "Note: Pos=-1 indicates that the key is not in the dataset.\n"
     ]
    }
   ],
   "source": [
    "## Use Delete, some examples\n",
    "\n",
    "# Delete single key\n",
    "keys = np.array([0.5])\n",
    "success = rmi_db.delete(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Delete single key:\")\n",
    "print(\" Success: {}\\n Key: {}\\n Pos after deletion: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "\n",
    "# Delete multiple keys\n",
    "keys = np.array([-42.0, -17.0, 0.2, 0.8, 17.0, 42.0])\n",
    "success = rmi_db.delete(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Delete multiple keys:\")\n",
    "print(\" Success: {}\\n Keys: {}\\n Pos after deletion: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "# Delete non-existing key\n",
    "keys = np.array([0.5])\n",
    "success = rmi_db.delete(keys)\n",
    "pos = rmi_db.select(keys)\n",
    "print(\"Delete non-existing key:\")\n",
    "print(\" Success: {}\\n Keys: {}\\n Pos after deletion: {}\\n\".format(np.squeeze(success),\n",
    "                                                   np.squeeze(keys),\n",
    "                                                   np.squeeze(pos)))\n",
    "\n",
    "print(\"Note: Pos=-1 indicates that the key is not in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Training:\n",
      "Step 0: loss = 38767.81 (0.045 sec, total 0.045 secs)\n",
      "Step 100: loss = 17584.88 (0.008 sec, total 0.388 secs)\n",
      "Step 200: loss = 5596.58 (0.006 sec, total 0.742 secs)\n",
      "Step 300: loss = 2403.03 (0.007 sec, total 1.078 secs)\n",
      "Step 400: loss = 1242.89 (0.006 sec, total 1.424 secs)\n",
      "\n",
      "Stage 2 Training:\n",
      "Step 0: loss = 102715.06 (0.054 sec, total 1.917 secs)\n",
      "Step 100: loss = 21269.79 (0.013 sec, total 2.831 secs)\n",
      "Step 200: loss = 2006.70 (0.012 sec, total 3.766 secs)\n",
      "Step 300: loss = 353.81 (0.012 sec, total 4.715 secs)\n",
      "Step 400: loss = 339.52 (0.012 sec, total 5.652 secs)\n",
      "INFO:tensorflow:Restoring parameters from tf_checkpoints_example/stage_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "## Retrain the model after many insertions and/or deletions.\n",
    "\n",
    "rmi_db.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
